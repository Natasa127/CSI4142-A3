{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Predictive analysis - Part 1: Linear Regression\n",
    "## Group 105\n",
    "- Natasa Bolic (300241734)\n",
    "- Brent Palmer (300193610)\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "**Url:** https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho <br>\n",
    "**Name:** Vehicle Dataset <br>\n",
    "**Author:** The author is not provided. However, the data is scraped from CarDekho, which is an online platform for selling and buying used cars in India. <br>\n",
    "**Purpose:** The dataset consists of features of used cars. One purpose of the dataset is to allow users to practice linear regression to predict car prices, as described on Kaggle. However, it does not appear that the dataset has one original purpose, it can be used for many car-related applications. <br>\n",
    "**Shape:** There are 4340 rows and 8 columns. (4340, 8)<br>\n",
    "**Features:**\n",
    "- `name` (categorical): The name of the car, including the car brand and the model name and variants.\n",
    "- `year` (numerical): TODO\n",
    "- `selling_price` (numerical): The price of the car.\n",
    "- `km_driven` (numerical): The number of kilometres that the car has been driven.\n",
    "- `fuel` (categorical): The fuel type of the car, which can be petrol, diesel, CNG, LPG or electric.\n",
    "- `seller_type` (categorical): The type of the seller, which can be either an individual or a dealer.\n",
    "- `transmission` (categorical): The car's gear transmission, which can be either automatic or manual.\n",
    "- `owner` (categorical): The number of individuals that have previously owned the car.\n",
    "\n",
    "Note: we have already used a dataset in the same domain (cars) in a previous assignment, but this is a different dataset with different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>2007</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>2007</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Datsun RediGO T Option</td>\n",
       "      <td>2017</td>\n",
       "      <td>250000</td>\n",
       "      <td>46000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honda Amaze VX i-DTEC</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>141000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  year  selling_price  km_driven    fuel  \\\n",
       "0             Maruti 800 AC  2007          60000      70000  Petrol   \n",
       "1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
       "2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
       "3    Datsun RediGO T Option  2017         250000      46000  Petrol   \n",
       "4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner  \n",
       "0  Individual       Manual   First Owner  \n",
       "1  Individual       Manual   First Owner  \n",
       "2  Individual       Manual   First Owner  \n",
       "3  Individual       Manual   First Owner  \n",
       "4  Individual       Manual  Second Owner  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset from a public repository\n",
    "url = \"https://raw.githubusercontent.com/Natasa127/CSI4142-A3/refs/heads/main/Dekho-Car-Details.csv\"\n",
    "car_df = pd.read_csv(url)\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4340 entries, 0 to 4339\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   name           4340 non-null   object\n",
      " 1   year           4340 non-null   int64 \n",
      " 2   selling_price  4340 non-null   int64 \n",
      " 3   km_driven      4340 non-null   int64 \n",
      " 4   fuel           4340 non-null   object\n",
      " 5   seller_type    4340 non-null   object\n",
      " 6   transmission   4340 non-null   object\n",
      " 7   owner          4340 non-null   object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 271.4+ KB\n"
     ]
    }
   ],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4340, 8)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Empirical Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Cleaning the data\n",
    "\n",
    "In this section, we will use the validity checks from `Assignment 2` to identify any invalid data. If needed, an imputation method may be used to clean the data. Note that we will be doing each of the ten validity checks, although they might be in a different order than in assignment 2. They will be clearly enumerated. Furthermore, in `Assignment 2`, we saved a copy of the invalid rows in our validity checks. In this assignment, we will first check the count of invalid rows; if there are none, we will omit the code that saves a copy, and displays invalid rows. If we find the error count to be non-zero, we will then clean it instead in addition to displaying some of the invalid values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 1: Exact Duplicates\n",
    "\n",
    "We first check for exact duplicates in the car dataset. This check verifies whether there are rows that are identical over all columns.\n",
    "\n",
    "**References:** <br>\n",
    "Exact Duplicates: https://uottawa.brightspace.com/d2l/le/content/490358/viewContent/6620388/View (Slide 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 763\n"
     ]
    }
   ],
   "source": [
    "# Exact duplicates check\n",
    "\n",
    "# Apply the .duplicated method to the DataFrame to create a Series, with exact duplicates set to True\n",
    "duplicates = car_df.duplicated()\n",
    "\n",
    "# Print the number of rows that are exact duplicates\n",
    "print(f\"Number of duplicate rows: {duplicates.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 763 exact duplicate rows, so we look into the actual rows to determine how to handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of three exact duplicate rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Maruti 800 AC</td>\n",
       "      <td>2007</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Maruti Wagon R LXI Minor</td>\n",
       "      <td>2007</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hyundai Verna 1.6 SX</td>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  year  selling_price  km_driven    fuel  \\\n",
       "13             Maruti 800 AC  2007          60000      70000  Petrol   \n",
       "14  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol   \n",
       "15      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel   \n",
       "\n",
       "   seller_type transmission        owner  \n",
       "13  Individual       Manual  First Owner  \n",
       "14  Individual       Manual  First Owner  \n",
       "15  Individual       Manual  First Owner  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the invalid rows\n",
    "invalid_exact_duplicate_df = car_df.loc[duplicates]\n",
    "\n",
    "# Display the first 3 rows that are exact duplicates\n",
    "print(\"Examples of three exact duplicate rows:\")\n",
    "invalid_exact_duplicate_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense that the rows have some attributes in common, such as cars with the same name having the same transmission. However, it is unlikely that two cars have exactly the same attributes, particularly due to the attribute `km_driven`, which depends greatly on the owners of the car (an attribute which is not recorded).\n",
    "\n",
    "A common tactic for sellers on online market platforms, like CarDekho, is to relist their product so that their listing appears newer and higher up in the page. So, we believe that these duplicates are likely due to multiple listings of the same cars. Since it is likely that the duplicated entries represent the same car, we believe it is justified to keep one of the duplicates and remove the rest. In other words, we handle the exact duplicates using listwise removal.\n",
    "\n",
    "In addition, we note that the number of entries deleted does not make up a very large proportion of the data, so we can delete the instances without worrying about compromising the quality of the rest of our analysis (there are still 3577 instances)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 3577\n"
     ]
    }
   ],
   "source": [
    "# Select the all the entries that were not duplicated, and the first instance of every duplicated entry\n",
    "cleaned_car_df = car_df.loc[~duplicates]\n",
    "# Print the number of valid entries remaining\n",
    "print(f\"Number of rows after removing duplicates: {len(cleaned_car_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 2: Format errors\n",
    "\n",
    "None of the features in this dataset have a specific format to be verified, so the format check does not apply here. Note that we could check that `year` is in the correct format, but since it is stored as an `integer` (and not a `datetime` object), we decide to check its validity through the datatype and range checks instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 3: Uniqueness errors\n",
    "\n",
    "None of the features in this dataset are intended to be unique, so the uniqueness check does not apply here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 4: Presence errors\n",
    "\n",
    "We will use the presence check from `Assignment 2` to verify whether there is missing data in any of the columns. Minimal changes are necessary to the code; instead of taking a parameter input, we will simply iterate over all of the columns to determine if any of them have missing values. We also added a check for strings of whitespace, which we qualify as a missing value as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where the name value is missing: 0\n",
      "Number of rows where the year value is missing: 0\n",
      "Number of rows where the selling_price value is missing: 0\n",
      "Number of rows where the km_driven value is missing: 0\n",
      "Number of rows where the fuel value is missing: 0\n",
      "Number of rows where the seller_type value is missing: 0\n",
      "Number of rows where the transmission value is missing: 0\n",
      "Number of rows where the owner value is missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Presence check\n",
    "\n",
    "# Iterate over each column and perform the presence check on each\n",
    "for column in cleaned_car_df:\n",
    "    # Apply pd.isna() to the test attribute, or check if it is a string of whitespace, setting rows with missing values in the designated column to True\n",
    "    invalid_presence = cleaned_car_df[column].apply(lambda attribute: (pd.isna(attribute) or (isinstance(attribute, str) and attribute.strip() == \"\")))\n",
    "\n",
    "    # Print the number of rows with a missing value in the chosen test attribute\n",
    "    print(f\"Number of rows where the {column} value is missing: {invalid_presence.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no missing values in any of the columns, no cleaning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 5: Length errors\n",
    "\n",
    "None of the features in this dataset are intended to be a specific length, so the length check does not apply here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 6: Look-up errors\n",
    "\n",
    "We will use the look-up check from `Assignment 2` to validate that the column values exist in a pre-defined finite set of values, if applicable. Minimal changes are necessary to the code from the previous assignment; we define a dictionary containing all of the relevant features along with their look-up tables. Then, we iterate over all of these features and apply the procedure from the previous assignment.\n",
    "\n",
    "**References:**<br>\n",
    "Boolean indexing: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where the fuel value is not in the look-up table: 0\n",
      "Number of rows where the seller_type value is not in the look-up table: 33\n",
      "Number of rows where the transmission value is not in the look-up table: 0\n",
      "Number of rows where the owner value is not in the look-up table: 0\n"
     ]
    }
   ],
   "source": [
    "# Validity check\n",
    "\n",
    "# Dictionary containing every feature's look-up table of valid values\n",
    "look_up_dict = {\n",
    "    \"fuel\": [\"Petrol\", \"Diesel\", \"CNG\", \"LPG\", \"Electric\"],\n",
    "    \"seller_type\": [\"Individual\", \"Dealer\"],\n",
    "    \"transmission\": [\"Automatic\", \"Manual\"],\n",
    "    \"owner\": [\"First Owner\", \"Second Owner\", \"Third Owner\", \"Fourth & Above Owner\", \"Test Drive Car\"]\n",
    "}\n",
    "\n",
    "# Checks if a single value is in the look-up table\n",
    "def look_up_filter(value, look_up_table):\n",
    "    return value in look_up_table\n",
    "\n",
    "# Apply the function to every feature, setting rows whose value is not in the look-up table to True\n",
    "for feature in look_up_dict.keys():\n",
    "    invalid_look_up = cleaned_car_df[feature].apply(\n",
    "        lambda attribute: not look_up_filter(attribute, look_up_dict[feature])\n",
    "    )\n",
    "    # Print the number of rows with a value that is not in the look-up table for the designated attribute\n",
    "    print(f\"Number of rows where the {feature} value is not in the look-up table: {invalid_look_up.sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are values that are not in the look-up table in the `seller_type` feature. We will investigate this further by determining what the invalid values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trustmark Dealer']\n"
     ]
    }
   ],
   "source": [
    "# Apply the check once again for `seller_type`\n",
    "feature = \"seller_type\"\n",
    "invalid_look_up = cleaned_car_df[feature].apply(\n",
    "    lambda attribute: not look_up_filter(attribute, look_up_dict[feature])\n",
    ")\n",
    "\n",
    "# Save the invalid rows\n",
    "invalid_look_up_df = cleaned_car_df.loc[invalid_look_up]\n",
    "\n",
    "# Determine what the invalid values are\n",
    "print(invalid_look_up_df[feature].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the invalid entries for `seller_type` have the value 'Trustmark Dealer'. Since the `seller_type` attribute is intended to indicate whether the seller is a dealer or an individual, we believe it is reasonable to impute the invalid values with 'Dealer' since a trustmark dealer is a type of dealer. We do this imputation below using boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_car_df.loc[invalid_look_up, 'seller_type'] = 'Dealer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 7: Consistency errors\n",
    "\n",
    "We believe that there are no relationships that need to be checked for consistency in the dataset. We could verify that cars with more kilometers driven have a lower price than cars with less kilometers driven, but this is not a strict rule. For example, the price should also depend on the maintenance of the car, which is not recorded. Additionally, the price should depend on many more factors such as the brand of the car. So, we do not believe that there exist strict rules that can be implemented in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validitity Check 8: Data type errors\n",
    "\n",
    "We will use the data type check from `Assignment 2`, specifically method 1 which checks if the data in a column is stored in the correct datatype, to validate that the data is properly stored and of the correct datatype. Minimal changes are necessary to the code; we define a dictionary mapping each feature to its correct datatype. Then, we iterate over all of these features and apply method 1 from the previous assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where the name value is not stored as the correct datatype (<class 'str'>): 0\n",
      "Number of rows where the year value is not stored as the correct datatype (<class 'int'>): 0\n",
      "Number of rows where the selling_price value is not stored as the correct datatype (<class 'int'>): 0\n",
      "Number of rows where the km_driven value is not stored as the correct datatype (<class 'int'>): 0\n",
      "Number of rows where the fuel value is not stored as the correct datatype (<class 'str'>): 0\n",
      "Number of rows where the seller_type value is not stored as the correct datatype (<class 'str'>): 0\n",
      "Number of rows where the transmission value is not stored as the correct datatype (<class 'str'>): 0\n",
      "Number of rows where the owner value is not stored as the correct datatype (<class 'str'>): 0\n"
     ]
    }
   ],
   "source": [
    "# Data type check\n",
    "\n",
    "# Evalutes a single value's data type against the desired data type\n",
    "def type_filter_method1(value, test_datatype):\n",
    "    if pd.isna(value):\n",
    "        return False\n",
    "    return isinstance(value, test_datatype)\n",
    "\n",
    "# Create a dictionary that maps each attribute to its correct datatype\n",
    "data_type_dict = {\n",
    "    \"name\": str,\n",
    "    \"year\": int,\n",
    "    \"selling_price\": int,\n",
    "    \"km_driven\": int,\n",
    "    \"fuel\": str,\n",
    "    \"seller_type\": str,\n",
    "    \"transmission\": str,\n",
    "    \"owner\": str\n",
    "}\n",
    "\n",
    "# Apply the function to every feature, setting rows whose value is not stored as the correct datatype to True\n",
    "for feature in data_type_dict.keys():\n",
    "    invalid_datatype = cleaned_car_df[feature].apply(\n",
    "        lambda attribute: not type_filter_method1(attribute, data_type_dict[feature])\n",
    "    )\n",
    "    # Print the number of rows with a value that is not stored as the correct datatype for the designated attribute\n",
    "    print(f\"Number of rows where the {feature} value is not stored as the correct datatype ({data_type_dict[feature]}): {invalid_datatype.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no values stored as the incorrect datatype in any of the columns, no cleaning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validitity Check 9: Range errors\n",
    "\n",
    "We will use the range check from `Assignment 2` to validate that the numerical data is in the correct range. Minimal changes are necessary to the code; we define a dictionary mapping each feature to its correct range. Then, we iterate over all of these features and apply the procedure from the previous assignment.\n",
    "\n",
    "We consider a reasonable range of possible years for cars on the market to be 1950 to the present. Since the selling price and number of kilometers driven cannot be negative, we set a minimum of 0. Based on an article about expensive car models in India, we find that a reasonable upper bound for possible prices is roughly 122500000 Rupees. Additionally, we choose a large number for the maximum number of kilometers driven.\n",
    "\n",
    "**References:**<br>\n",
    "Most expensive cars in India: https://northfleet.in/expensive-car-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where the year value is not in the correct range: 0\n",
      "Number of rows where the selling_price value is not in the correct range: 0\n",
      "Number of rows where the km_driven value is not in the correct range: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary that maps each numerical attribute to its acceptable range in the format [min, max]\n",
    "range_dict = {\n",
    "    \"year\": [1950, 2025],\n",
    "    \"selling_price\": [0, 122500000],\n",
    "    \"km_driven\": [0, 5000000]\n",
    "}\n",
    "\n",
    "# Evaluates a single value against a given range\n",
    "def range_filter(value, minimum, maximum):\n",
    "    try:\n",
    "        value = float(value)\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    return minimum <= value <= maximum\n",
    "\n",
    "# Apply the function to every feature in the dictionary, setting out of range values to True\n",
    "for feature in range_dict.keys():\n",
    "    invalid_range = cleaned_car_df[feature].apply(\n",
    "        lambda attribute: not range_filter(attribute, range_dict[feature][0], range_dict[feature][1])\n",
    "    )\n",
    "    # Print the number of rows with a value that is not stored as the correct datatype for the designated attribute\n",
    "    print(f\"Number of rows where the {feature} value is not in the correct range {range_dict[feature]}: {invalid_range.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no values outside of the correct range, no cleaning is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validity Check 10: Near Duplicate Errors\n",
    "\n",
    "Our near duplicate check finds rows that differ only by a synonym in a designated attribute. There are no attributes in our dataset with synonyms for a term, which we check by observing the unique values in every categorical variable. Note that we do not check for the `name` attribute since there are over 1400 unique values, and we do not consider it as a predictor in the analysis (which is justified in the Categorical feature encoding section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491\n"
     ]
    }
   ],
   "source": [
    "# Print the number of unique car names\n",
    "print(cleaned_car_df['name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Petrol' 'Diesel' 'CNG' 'LPG' 'Electric']\n",
      "['Individual' 'Dealer']\n",
      "['Manual' 'Automatic']\n",
      "['First Owner' 'Second Owner' 'Fourth & Above Owner' 'Third Owner'\n",
      " 'Test Drive Car']\n"
     ]
    }
   ],
   "source": [
    "# Print the unique values of the categorical features\n",
    "print(cleaned_car_df['fuel'].unique())\n",
    "print(cleaned_car_df['seller_type'].unique())\n",
    "print(cleaned_car_df['transmission'].unique())\n",
    "print(cleaned_car_df['owner'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this check does not apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical feature encoding\n",
    "\n",
    "There are 5 five categorical features in this dataset: `name`, `fuel`, `seller_type`, `transmission` and `owner`. \n",
    "\n",
    "Since there are 1491 unique car names, we do not encode this feature, as it would produce 1491 additional columns. Moreover, since there are so many unique values, we do not believe that this feature would provide a lot of insight to the analysis. Thus, since it cannot be used in the linear regression model as a categorical feature, we drop it. We encode the rest of the categorical variables below using one-hot encoding.\n",
    "\n",
    "**References:**<br>\n",
    "One-hot encoding: https://www.geeksforgeeks.org/ml-one-hot-encoding/ <br>\n",
    "Drop a column: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel_CNG</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_Electric</th>\n",
       "      <th>fuel_LPG</th>\n",
       "      <th>fuel_Petrol</th>\n",
       "      <th>seller_type_Dealer</th>\n",
       "      <th>seller_type_Individual</th>\n",
       "      <th>transmission_Automatic</th>\n",
       "      <th>transmission_Manual</th>\n",
       "      <th>owner_First Owner</th>\n",
       "      <th>owner_Fourth &amp; Above Owner</th>\n",
       "      <th>owner_Second Owner</th>\n",
       "      <th>owner_Test Drive Car</th>\n",
       "      <th>owner_Third Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>60000</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>135000</td>\n",
       "      <td>50000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>600000</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  selling_price  km_driven  fuel_CNG  fuel_Diesel  fuel_Electric  \\\n",
       "0  2007          60000      70000         0            0              0   \n",
       "1  2007         135000      50000         0            0              0   \n",
       "2  2012         600000     100000         0            1              0   \n",
       "\n",
       "   fuel_LPG  fuel_Petrol  seller_type_Dealer  seller_type_Individual  \\\n",
       "0         0            1                   0                       1   \n",
       "1         0            1                   0                       1   \n",
       "2         0            0                   0                       1   \n",
       "\n",
       "   transmission_Automatic  transmission_Manual  owner_First Owner  \\\n",
       "0                       0                    1                  1   \n",
       "1                       0                    1                  1   \n",
       "2                       0                    1                  1   \n",
       "\n",
       "   owner_Fourth & Above Owner  owner_Second Owner  owner_Test Drive Car  \\\n",
       "0                           0                   0                     0   \n",
       "1                           0                   0                     0   \n",
       "2                           0                   0                     0   \n",
       "\n",
       "   owner_Third Owner  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply one-hot encoding\n",
    "car_df_encoded = pd.get_dummies(cleaned_car_df, columns=['fuel', 'seller_type', 'transmission', 'owner'])\n",
    "# Drop the `name` feature\n",
    "car_df_encoded = car_df_encoded.drop(\"name\", axis = 1)\n",
    "# Display the first 3 rows\n",
    "car_df_encoded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Train Split\n",
    "\n",
    "We split the data such that 20% is reserved as a test set and the remaining 80% is used as the training set. Note that we will use 4-fold cross validation on the training set in a later step, which will involve creating 4 validation sets from the training set that we define in this section. So, we do not separate a validation set in this step (as specified by the professor).\n",
    "\n",
    "**References:**<br>\n",
    "isin method: https://www.w3schools.com/python/pandas/ref_df_isin.asp <br>\n",
    "Train test split: https://www.geeksforgeeks.org/how-to-do-train-test-split-using-sklearn-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the features that will be used to train the model\n",
    "X = car_df_encoded.loc[:, ~car_df_encoded.columns.isin(['selling_price'])]\n",
    "# Select the target feature\n",
    "y = car_df_encoded['selling_price']\n",
    "# Split the data into the test set and the training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Outlier detection\n",
    "\n",
    "doing this later too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive analysis: Linear regression\n",
    "\n",
    "**References:**<br>\n",
    "Linear regression: https://www.geeksforgeeks.org/python-linear-regression-using-sklearn/ <br>\n",
    "Linear regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html <br>\n",
    "Cross validation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html <br>\n",
    "Scoring with MSE: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Scores: [0.36653681 0.45453508 0.50614329 0.45015784]\n",
      "Mean: 0.44\n",
      "Standard deviation: 0.05\n",
      "\n",
      "MSE Scores: [-2.10600627e+11 -1.42978551e+11 -9.84487209e+10 -1.26816709e+11]\n",
      "Mean: -144711152112.83\n",
      "Standard deviation: 41245752669.13\n"
     ]
    }
   ],
   "source": [
    "# Create the linear regression model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Train the model and calculate evaluation metrics using cross validation on the training set\n",
    "scoring_metrics = ['r2', 'neg_mean_squared_error']\n",
    "scores = cross_validate(reg, X_train, y_train, scoring=scoring_metrics, cv=4)\n",
    "\n",
    "# Print R^2 scores from the cross validation\n",
    "R_squared_scores = scores['test_r2']\n",
    "print(\"R^2 Scores:\", R_squared_scores)\n",
    "print(f\"Mean: {R_squared_scores.mean():.2f}\")\n",
    "print(f\"Standard deviation: {R_squared_scores.std():.2f}\")\n",
    "\n",
    "# Print MSE scores from the cross validation\n",
    "MSE_scores = scores['test_neg_mean_squared_error']\n",
    "print(\"\\nMSE Scores:\", MSE_scores)\n",
    "print(f\"Mean: {MSE_scores.mean():.2f}\")\n",
    "print(f\"Standard deviation: {MSE_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
